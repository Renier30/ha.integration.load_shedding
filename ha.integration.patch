diff --git a/custom_components/load_shedding/__init__.py b/custom_components/load_shedding/__init__.py
index 5f3b609..ef79d74 100644
--- a/custom_components/load_shedding/__init__.py
+++ b/custom_components/load_shedding/__init__.py
@@ -44,6 +44,7 @@ from .const import (
     ATTR_STAGE,
     ATTR_START_TIME,
     CONF_AREAS,
+    CONF_MIN_EVENT_DURATION,
     DEFAULT_SCAN_INTERVAL,
     DOMAIN,
     MANUFACTURER,
@@ -53,7 +54,7 @@ from .const import (
 
 _LOGGER = logging.getLogger(__name__)
 
-PLATFORMS = [Platform.SENSOR, Platform.CALENDAR]
+PLATFORMS = [Platform.BINARY_SENSOR, Platform.SENSOR, Platform.CALENDAR]
 
 
 async def async_setup(hass: HomeAssistant, config: ConfigType) -> bool:
@@ -61,45 +62,52 @@ async def async_setup(hass: HomeAssistant, config: ConfigType) -> bool:
     return True
 
 
-async def async_setup_entry(hass: HomeAssistant, entry: ConfigEntry) -> bool:
+async def async_setup_entry(hass: HomeAssistant, config_entry: ConfigEntry) -> bool:
     """Set up LoadShedding as config entry."""
-    api_key: str = entry.data.get(CONF_API_KEY)
-    sepush: SePush = SePush(token=api_key)
     if not hass.data.get(DOMAIN):
         hass.data.setdefault(DOMAIN, {})
 
+    sepush: SePush = None
+    if api_key := config_entry.options.get(CONF_API_KEY):
+        sepush: SePush = SePush(token=api_key)
+    if not sepush:
+        return False
+
     stage_coordinator = LoadSheddingStageCoordinator(hass, sepush)
     stage_coordinator.update_interval = timedelta(
-        seconds=entry.options.get(CONF_SCAN_INTERVAL, DEFAULT_SCAN_INTERVAL)
+        seconds=config_entry.options.get(CONF_SCAN_INTERVAL, DEFAULT_SCAN_INTERVAL)
     )
-    await stage_coordinator.async_config_entry_first_refresh()
 
     area_coordinator = LoadSheddingAreaCoordinator(
         hass, sepush, stage_coordinator=stage_coordinator
     )
     area_coordinator.update_interval = timedelta(
-        seconds=entry.options.get(CONF_SCAN_INTERVAL, DEFAULT_SCAN_INTERVAL)
+        seconds=config_entry.options.get(CONF_SCAN_INTERVAL, DEFAULT_SCAN_INTERVAL)
     )
-    for conf in entry.options.get(CONF_AREAS, []).values():
+    for conf in config_entry.options.get(CONF_AREAS, {}).values():
         area = Area(
             id=conf.get(CONF_ID),
             name=conf.get(CONF_NAME),
         )
         area_coordinator.add_area(area)
-    await area_coordinator.async_config_entry_first_refresh()
+    if not area_coordinator.areas:
+        return False
 
     quota_coordinator = LoadSheddingQuotaCoordinator(hass, sepush)
     quota_coordinator.update_interval = timedelta(seconds=QUOTA_UPDATE_INTERVAL)
-    await quota_coordinator.async_config_entry_first_refresh()
 
-    hass.data[DOMAIN][entry.entry_id] = {
+    hass.data[DOMAIN][config_entry.entry_id] = {
         ATTR_STAGE: stage_coordinator,
         ATTR_AREA: area_coordinator,
         ATTR_QUOTA: quota_coordinator,
     }
 
-    entry.async_on_unload(entry.add_update_listener(update_listener))
-    await hass.config_entries.async_forward_entry_setups(entry, PLATFORMS)
+    config_entry.async_on_unload(config_entry.add_update_listener(update_listener))
+
+    await stage_coordinator.async_config_entry_first_refresh()
+    await area_coordinator.async_config_entry_first_refresh()
+    await quota_coordinator.async_config_entry_first_refresh()
+    await hass.config_entries.async_forward_entry_setups(config_entry, PLATFORMS)
 
     return True
 
@@ -112,20 +120,33 @@ async def async_unload_entry(hass: HomeAssistant, config_entry: ConfigEntry) ->
     return unload_ok
 
 
-async def async_reload_entry(hass: HomeAssistant, entry: ConfigEntry):
+async def async_reload_entry(hass: HomeAssistant, config_entry: ConfigEntry):
     """Reload config entry."""
-    await hass.config_entries.async_reload(entry.entry_id)
+    await hass.config_entries.async_reload(config_entry.entry_id)
 
 
-async def update_listener(hass: HomeAssistant, entry: ConfigEntry) -> bool:
+async def update_listener(hass: HomeAssistant, config_entry: ConfigEntry) -> bool:
     """Update listener."""
-    return await hass.config_entries.async_reload(entry.entry_id)
+    return await hass.config_entries.async_reload(config_entry.entry_id)
 
 
 async def async_migrate_entry(hass: HomeAssistant, config_entry: ConfigEntry) -> bool:
     """Migrate old entry."""
     _LOGGER.debug("Migrating from version %s", config_entry.version)
 
+    if config_entry.version == 3:
+        old_data = {**config_entry.data}
+        old_options = {**config_entry.options}
+        new_data = {}
+        new_options = {
+            CONF_API_KEY: old_data.get(CONF_API_KEY),
+            CONF_AREAS: old_options.get(CONF_AREAS, {}),
+        }
+        config_entry.version = 4
+        hass.config_entries.async_update_entry(
+            config_entry, data=new_data, options=new_options
+        )
+
     _LOGGER.info("Migration to version %s successful", config_entry.version)
     return True
 
@@ -139,8 +160,9 @@ class LoadSheddingStageCoordinator(DataUpdateCoordinator[dict[str, Any]]):
         self.data = {}
         self.sepush = sepush
         self.last_update: datetime | None = None
+        self.update_method = self.update_stage
 
-    async def _async_update_data(self) -> dict:
+    async def update_stage(self) -> dict:
         """Retrieve latest load shedding data."""
 
         now = datetime.now(timezone.utc).replace(microsecond=0)
@@ -238,12 +260,13 @@ class LoadSheddingAreaCoordinator(DataUpdateCoordinator[dict[str, Any]]):
         self.last_update: datetime | None = None
         self.areas: list[Area] = []
         self.stage_coordinator = stage_coordinator
+        self.update_method = self.update_area
 
     def add_area(self, area: Area = None) -> None:
         """Add a area to update."""
         self.areas.append(area)
 
-    async def _async_update_data(self) -> dict:
+    async def update_area(self) -> dict:
         """Retrieve latest load shedding data."""
 
         now = datetime.now(timezone.utc).replace(microsecond=0)
@@ -268,17 +291,17 @@ class LoadSheddingAreaCoordinator(DataUpdateCoordinator[dict[str, Any]]):
         return self.data
 
     async def async_update_area(self) -> dict:
-        """Retrieve schedule data."""
-        areas_stage_schedules: dict = {}
+        """Retrieve area data."""
+        area_id_data: dict = {}
 
         for area in self.areas:
-            # Get forecast for area
-            events = []
             try:
                 esp = await self.hass.async_add_executor_job(self.sepush.area, area.id)
             except SePushError as err:
                 raise UpdateFailed(err) from err
 
+            # Get events for area
+            events = []
             for event in esp.get("events", {}):
                 note = event.get("note")
                 parts = str(note).split(" ")
@@ -298,7 +321,6 @@ class LoadSheddingAreaCoordinator(DataUpdateCoordinator[dict[str, Any]]):
 
             # Get schedule for area
             stage_schedule = {}
-            sast = timezone(timedelta(hours=+2), "SAST")
             for day in esp.get("schedule", {}).get("days", []):
                 date = datetime.strptime(day.get("date"), "%Y-%m-%d")
                 stage_timeslots = day.get("stages", [])
@@ -308,30 +330,8 @@ class LoadSheddingAreaCoordinator(DataUpdateCoordinator[dict[str, Any]]):
                         stage_schedule[stage] = []
                     for timeslot in timeslots:
                         start_str, end_str = timeslot.strip().split("-")
-                        start = (
-                            datetime.strptime(start_str, "%H:%M")
-                            .replace(
-                                year=date.year,
-                                month=date.month,
-                                day=date.day,
-                                second=0,
-                                microsecond=0,
-                                tzinfo=sast,
-                            )
-                            .astimezone(timezone.utc)
-                        )
-                        end = (
-                            datetime.strptime(end_str, "%H:%M")
-                            .replace(
-                                year=date.year,
-                                month=date.month,
-                                day=date.day,
-                                second=0,
-                                microsecond=0,
-                                tzinfo=sast,
-                            )
-                            .astimezone(timezone.utc)
-                        )
+                        start = utc_dt(date, datetime.strptime(start_str, "%H:%M"))
+                        end = utc_dt(date, datetime.strptime(end_str, "%H:%M"))
                         if end < start:
                             end = end + timedelta(days=1)
                         stage_schedule[stage].append(
@@ -342,12 +342,12 @@ class LoadSheddingAreaCoordinator(DataUpdateCoordinator[dict[str, Any]]):
                             }
                         )
 
-            areas_stage_schedules[area.id] = {
+            area_id_data[area.id] = {
                 ATTR_EVENTS: events,
                 ATTR_SCHEDULE: stage_schedule,
             }
 
-        return areas_stage_schedules
+        return area_id_data
 
     async def async_area_forecast(self) -> None:
         """Derive area forecast from planned stages and area schedule."""
@@ -359,8 +359,6 @@ class LoadSheddingAreaCoordinator(DataUpdateCoordinator[dict[str, Any]]):
         eskom_stages = stages.get(eskom, {}).get(ATTR_PLANNED, [])
         cape_town_stages = stages.get(cape_town, {}).get(ATTR_PLANNED, [])
 
-        now = datetime.now(timezone.utc)
-
         for area_id, data in self.data.items():
             stage_schedules = data.get(ATTR_SCHEDULE)
 
@@ -382,9 +380,6 @@ class LoadSheddingAreaCoordinator(DataUpdateCoordinator[dict[str, Any]]):
                     start_time = timeslot.get(ATTR_START_TIME)
                     end_time = timeslot.get(ATTR_END_TIME)
 
-                    # if end_time < now:
-                    #     continue
-
                     if start_time >= planned_end_time:
                         continue
                     if end_time <= planned_start_time:
@@ -405,6 +400,13 @@ class LoadSheddingAreaCoordinator(DataUpdateCoordinator[dict[str, Any]]):
                     if start_time == end_time:
                         continue
 
+                    # Minimum event duration
+                    min_event_dur = self.stage_coordinator.config_entry.options.get(
+                        CONF_MIN_EVENT_DURATION, 30
+                    )  # minutes
+                    if end_time - start_time < timedelta(minutes=min_event_dur):
+                        continue
+
                     forecast.append(
                         {
                             ATTR_STAGE: planned_stage,
@@ -416,6 +418,20 @@ class LoadSheddingAreaCoordinator(DataUpdateCoordinator[dict[str, Any]]):
             data[ATTR_FORECAST] = forecast
 
 
+def utc_dt(date: datetime, time: datetime) -> datetime:
+    """Given a date and time in SAST, this function returns a datetime object in UTC"""
+    sast = timezone(timedelta(hours=+2), "SAST")
+
+    return time.replace(
+        year=date.year,
+        month=date.month,
+        day=date.day,
+        second=0,
+        microsecond=0,
+        tzinfo=sast,
+    ).astimezone(timezone.utc)
+
+
 class LoadSheddingQuotaCoordinator(DataUpdateCoordinator[dict[str, Any]]):
     """Class to manage fetching LoadShedding Quota."""
 
@@ -425,8 +441,9 @@ class LoadSheddingQuotaCoordinator(DataUpdateCoordinator[dict[str, Any]]):
         self.data = {}
         self.sepush = sepush
         self.last_update: datetime | None = None
+        self.update_method = self.update_quota
 
-    async def _async_update_data(self) -> dict:
+    async def update_quota(self) -> dict:
         """Retrieve latest load shedding data."""
 
         now = datetime.now(timezone.utc).replace(microsecond=0)
diff --git a/custom_components/load_shedding/__pycache__/__init__.cpython-39.pyc b/custom_components/load_shedding/__pycache__/__init__.cpython-39.pyc
new file mode 100644
index 0000000..a0eb8f9
Binary files /dev/null and b/custom_components/load_shedding/__pycache__/__init__.cpython-39.pyc differ
diff --git a/custom_components/load_shedding/__pycache__/binary_sensor.cpython-39.pyc b/custom_components/load_shedding/__pycache__/binary_sensor.cpython-39.pyc
new file mode 100644
index 0000000..d335e34
Binary files /dev/null and b/custom_components/load_shedding/__pycache__/binary_sensor.cpython-39.pyc differ
diff --git a/custom_components/load_shedding/__pycache__/calendar.cpython-39.pyc b/custom_components/load_shedding/__pycache__/calendar.cpython-39.pyc
new file mode 100644
index 0000000..fb63c6a
Binary files /dev/null and b/custom_components/load_shedding/__pycache__/calendar.cpython-39.pyc differ
diff --git a/custom_components/load_shedding/__pycache__/config_flow.cpython-39.pyc b/custom_components/load_shedding/__pycache__/config_flow.cpython-39.pyc
new file mode 100644
index 0000000..df6a214
Binary files /dev/null and b/custom_components/load_shedding/__pycache__/config_flow.cpython-39.pyc differ
diff --git a/custom_components/load_shedding/__pycache__/const.cpython-39.pyc b/custom_components/load_shedding/__pycache__/const.cpython-39.pyc
new file mode 100644
index 0000000..c01f323
Binary files /dev/null and b/custom_components/load_shedding/__pycache__/const.cpython-39.pyc differ
diff --git a/custom_components/load_shedding/__pycache__/sensor.cpython-39.pyc b/custom_components/load_shedding/__pycache__/sensor.cpython-39.pyc
new file mode 100644
index 0000000..cfc9f97
Binary files /dev/null and b/custom_components/load_shedding/__pycache__/sensor.cpython-39.pyc differ
diff --git a/custom_components/load_shedding/binary_sensor.py b/custom_components/load_shedding/binary_sensor.py
new file mode 100644
index 0000000..79cbd7f
--- /dev/null
+++ b/custom_components/load_shedding/binary_sensor.py
@@ -0,0 +1,301 @@
+"""Support for the LoadShedding service."""
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime, timedelta, timezone
+from typing import Any, cast
+
+from homeassistant.components.sensor import RestoreSensor
+from homeassistant.components.binary_sensor import (
+    BinarySensorEntityDescription,
+    BinarySensorEntity,
+    BinarySensorDeviceClass,
+)
+from homeassistant.config_entries import ConfigEntry
+from homeassistant.const import (
+    ATTR_ATTRIBUTION,
+    STATE_ON,
+    STATE_OFF,
+)
+from homeassistant.core import HomeAssistant, callback
+from homeassistant.helpers.entity import Entity
+from homeassistant.helpers.entity_platform import AddEntitiesCallback
+from homeassistant.helpers.typing import StateType
+from homeassistant.helpers.update_coordinator import (
+    CoordinatorEntity,
+)
+
+from load_shedding.providers import Area, Stage
+from . import LoadSheddingDevice
+from .const import (
+    ATTR_AREA,
+    ATTR_END_IN,
+    ATTR_END_TIME,
+    ATTR_FORECAST,
+    ATTR_LAST_UPDATE,
+    ATTR_NEXT_END_TIME,
+    ATTR_NEXT_STAGE,
+    ATTR_NEXT_START_TIME,
+    ATTR_PLANNED,
+    ATTR_QUOTA,
+    ATTR_SCHEDULE,
+    ATTR_STAGE,
+    ATTR_START_IN,
+    ATTR_START_TIME,
+    ATTRIBUTION,
+    DOMAIN,
+    NAME,
+)
+
+DEFAULT_DATA = {
+    ATTR_STAGE: Stage.NO_LOAD_SHEDDING.value,
+    ATTR_START_TIME: 0,
+    ATTR_END_TIME: 0,
+    ATTR_END_IN: 0,
+    ATTR_START_IN: 0,
+    ATTR_NEXT_STAGE: Stage.NO_LOAD_SHEDDING.value,
+    ATTR_NEXT_START_TIME: 0,
+    ATTR_NEXT_END_TIME: 0,
+    ATTR_PLANNED: [],
+    ATTR_FORECAST: [],
+    ATTR_SCHEDULE: [],
+    ATTR_LAST_UPDATE: None,
+    ATTR_ATTRIBUTION: ATTRIBUTION.format(provider="sepush.co.za"),
+}
+
+CLEAN_DATA = {
+    ATTR_PLANNED: [],
+    ATTR_FORECAST: [],
+    ATTR_SCHEDULE: [],
+}
+
+
+async def async_setup_entry(
+    hass: HomeAssistant, entry: ConfigEntry, async_add_entities: AddEntitiesCallback
+) -> None:
+    """Add LoadShedding entities from a config_entry."""
+    coordinators = hass.data.get(DOMAIN, {}).get(entry.entry_id)
+    area_coordinator = coordinators.get(ATTR_AREA)
+
+    entities: list[Entity] = []
+    for area in area_coordinator.areas:
+        area_entity = LoadSheddingAreaBinarySensorEntity(area_coordinator, area)
+        entities.append(area_entity)
+
+    async_add_entities(entities)
+
+
+@dataclass
+class LoadSheddingBinarySensorDescription(BinarySensorEntityDescription):
+    """Class describing LoadShedding sensor entities."""
+
+
+class LoadSheddingAreaBinarySensorEntity(
+    LoadSheddingDevice,
+    CoordinatorEntity,
+    # RestoreSensor,
+    BinarySensorEntity,
+):
+    """Define a LoadShedding Area sensor entity."""
+
+    coordinator: CoordinatorEntity
+
+    def __init__(self, coordinator: CoordinatorEntity, area: Area) -> None:
+        """Initialize."""
+        super().__init__(coordinator)
+        self.area = area
+        self.data = self.coordinator.data.get(self.area.id)
+        self._sensor_type = BinarySensorDeviceClass.POWER
+
+        self.entity_description = LoadSheddingBinarySensorDescription(
+            # key=f"{DOMAIN} schedule {area.id}",
+            # icon="mdi:calendar",
+            # name=f"{DOMAIN} schedule {area.name}",
+            # entity_registry_enabled_default=True,
+            key=f"{DOMAIN} schedule {area.id}",
+            name=f"{DOMAIN} schedule {area.name}",
+            device_class=BinarySensorDeviceClass.POWER,
+            # entity_category=EntityCategory.DIAGNOSTIC,
+            # on_state=0,
+        )
+        self._attr_unique_id = (
+            f"{self.coordinator.config_entry.entry_id}_Binarysensor_{area.id}"
+        )
+        self.entity_id = f"{DOMAIN}.{DOMAIN}_area_{area.id}"
+
+    async def async_added_to_hass(self) -> None:
+        """Handle entity which will be added."""
+        # if restored_data := await self.async_get_last_sensor_data():
+        #     self._attr_native_value = restored_data.native_value
+        await super().async_added_to_hass()
+
+    @property
+    def name(self) -> str | None:
+        return self.area.name
+
+    @property
+    def is_on(self) -> bool:
+        """Return true if the binary sensor is on."""
+        return True
+
+    @property
+    def native_value(self) -> StateType:
+        """Return the area state."""
+        if not self.data:
+            return self._attr_is_on
+            return self._attr_native_value
+
+        events = self.data.get(ATTR_FORECAST, [])
+
+        if not events:
+            return STATE_OFF
+
+        now = datetime.now(timezone.utc)
+
+        for event in events:
+            if ATTR_END_TIME in event and event.get(ATTR_END_TIME) < now:
+                continue
+
+            if event.get(ATTR_START_TIME) <= now <= event.get(ATTR_END_TIME):
+                self._attr_native_value = cast(StateType, STATE_ON)
+                self._attr_is_on = cast(StateType, STATE_ON)
+                break
+
+            if event.get(ATTR_START_TIME) > now:
+                self._attr_native_value = cast(StateType, STATE_OFF)
+                self._attr_is_on = cast(StateType, STATE_OFF)
+                break
+
+            if event.get(ATTR_STAGE) == Stage.NO_LOAD_SHEDDING:
+                self._attr_native_value = cast(StateType, STATE_OFF)
+                self._attr_is_on = cast(StateType, STATE_OFF)
+                break
+
+        return self._attr_is_on
+        return self._attr_native_value
+
+    # @property
+    # def is_on(self) -> bool | None:
+    #     return self.native_value == STATE_OFF
+
+    @property
+    def extra_state_attributes(self) -> dict[str, list, Any]:
+        """Return the state attributes."""
+        if not hasattr(self, "_attr_extra_state_attributes"):
+            self._attr_extra_state_attributes = {}
+
+        if not self.data:
+            return self._attr_extra_state_attributes
+
+        now = datetime.now(timezone.utc)
+        data = dict(self._attr_extra_state_attributes)
+        if events := self.data.get(ATTR_FORECAST, []):
+            data[ATTR_FORECAST] = []
+            for event in events:
+                if ATTR_END_TIME in event and event.get(ATTR_END_TIME) < now:
+                    continue
+
+                forecast = {
+                    ATTR_STAGE: event.get(ATTR_STAGE),
+                    ATTR_START_TIME: event.get(ATTR_START_TIME),
+                    ATTR_END_TIME: event.get(ATTR_END_TIME),
+                }
+
+                data[ATTR_FORECAST].append(forecast)
+
+        forecast = []
+        if ATTR_FORECAST in data:
+            forecast = data[ATTR_FORECAST]
+
+        attrs = get_sensor_attrs(forecast)
+        attrs[ATTR_FORECAST] = forecast
+        attrs[ATTR_LAST_UPDATE] = self.coordinator.last_update
+        attrs = clean(attrs)
+
+        self._attr_extra_state_attributes.update(attrs)
+        return self._attr_extra_state_attributes
+
+    @callback
+    def _handle_coordinator_update(self) -> None:
+        """Handle updated data from the coordinator."""
+        if data := self.coordinator.data:
+            self.data = data.get(self.area.id)
+            self.async_write_ha_state()
+
+
+def stage_forecast_to_data(stage_forecast: list) -> list:
+    """Convert stage forecast to serializable data"""
+    data = []
+    for forecast in stage_forecast:
+        for schedule in forecast.get(ATTR_SCHEDULE, []):
+            data.append(
+                {
+                    ATTR_STAGE: forecast.get(ATTR_STAGE).value,
+                    ATTR_START_TIME: schedule[0].isoformat(),
+                    ATTR_END_TIME: schedule[1].isoformat(),
+                }
+            )
+    return data
+
+
+def get_sensor_attrs(forecast: list, stage: Stage = Stage.NO_LOAD_SHEDDING) -> dict:
+    """Get Binarysensor attributes for the given forecast and stage"""
+    if not forecast:
+        return {
+            ATTR_STAGE: stage.value,
+        }
+
+    now = datetime.now(timezone.utc)
+    data = dict(DEFAULT_DATA)
+    data[ATTR_STAGE] = stage.value
+
+    cur, nxt = {}, {}
+    if now < forecast[0].get(ATTR_START_TIME):
+        # before
+        nxt = forecast[0]
+    elif forecast[0].get(ATTR_START_TIME) <= now <= forecast[0].get(ATTR_END_TIME, now):
+        # during
+        cur = forecast[0]
+        if len(forecast) > 1:
+            nxt = forecast[1]
+    elif forecast[0].get(ATTR_END_TIME) < now:
+        # after
+        if len(forecast) > 1:
+            nxt = forecast[1]
+
+    if cur:
+        data[ATTR_STAGE] = cur.get(ATTR_STAGE).value
+        data[ATTR_START_TIME] = cur.get(ATTR_START_TIME).isoformat()
+        if ATTR_END_TIME in cur:
+            data[ATTR_END_TIME] = cur.get(ATTR_END_TIME).isoformat()
+
+            end_time = cur.get(ATTR_END_TIME)
+            ends_in = end_time - now
+            ends_in = ends_in - timedelta(microseconds=ends_in.microseconds)
+            ends_in = int(ends_in.total_seconds() / 60)  # minutes
+            data[ATTR_END_IN] = ends_in
+
+    if nxt:
+        data[ATTR_NEXT_STAGE] = nxt.get(ATTR_STAGE).value
+        data[ATTR_NEXT_START_TIME] = nxt.get(ATTR_START_TIME).isoformat()
+        if ATTR_END_TIME in nxt:
+            data[ATTR_NEXT_END_TIME] = nxt.get(ATTR_END_TIME).isoformat()
+
+        start_time = nxt.get(ATTR_START_TIME)
+        starts_in = start_time - now
+        starts_in = starts_in - timedelta(microseconds=starts_in.microseconds)
+        starts_in = int(starts_in.total_seconds() / 60)  # minutes
+        data[ATTR_START_IN] = starts_in
+
+    return data
+
+
+def clean(data: dict) -> dict:
+    """Remove default values from dict"""
+    for (key, value) in CLEAN_DATA.items():
+        if key not in data:
+            continue
+        if data[key] == value:
+            del data[key]
+
+    return data
diff --git a/custom_components/load_shedding/calendar.py b/custom_components/load_shedding/calendar.py
index a7c7d75..56da588 100644
--- a/custom_components/load_shedding/calendar.py
+++ b/custom_components/load_shedding/calendar.py
@@ -24,6 +24,7 @@ from .const import (
     ATTR_START_TIME,
     DOMAIN,
     NAME,
+    CONF_MULTI_STAGE_EVENTS,
 )
 
 
@@ -34,7 +35,13 @@ async def async_setup_entry(
     coordinators = hass.data.get(DOMAIN, {}).get(entry.entry_id)
     area_coordinator = coordinators.get(ATTR_AREA)
 
-    entities: list[Entity] = [LoadSheddingForecastCalendar(area_coordinator)]
+    multi_stage_events = False
+    if entry.options.get(CONF_MULTI_STAGE_EVENTS):
+        multi_stage_events = True
+
+    entities: list[Entity] = [
+        LoadSheddingForecastCalendar(area_coordinator, multi_stage_events)
+    ]
     async_add_entities(entities)
 
 
@@ -43,7 +50,9 @@ class LoadSheddingForecastCalendar(
 ):
     """Define a LoadShedding Calendar entity."""
 
-    def __init__(self, coordinator: CoordinatorEntity) -> None:
+    def __init__(
+        self, coordinator: CoordinatorEntity, multi_stage_events: bool
+    ) -> None:
         super().__init__(coordinator)
         self.data = self.coordinator.data
 
@@ -52,6 +61,7 @@ class LoadSheddingForecastCalendar(
         )
         self._event: CalendarEvent | None = None
         self.entity_id = f"{DOMAIN}.{DOMAIN}_forecast"
+        self.multi_stage_events = multi_stage_events
 
     @property
     def name(self) -> str | None:
@@ -93,6 +103,19 @@ class LoadSheddingForecastCalendar(
                     )
                     events.append(event)
 
+                if not self.multi_stage_events:
+                    continue
+
+                # Multi-stage events
+                for i, cur in enumerate(events):
+                    if i + 1 >= len(events):
+                        continue
+                    nxt = events[i + 1]
+                    if cur.end == nxt.start:
+                        cur.summary = f"{cur.summary}/{nxt.summary}"
+                        cur.end = nxt.end
+                        del events[i + 1]
+
         if events:
             self._event = events[0]
 
diff --git a/custom_components/load_shedding/config_flow.py b/custom_components/load_shedding/config_flow.py
index f61e2a4..2b537ba 100644
--- a/custom_components/load_shedding/config_flow.py
+++ b/custom_components/load_shedding/config_flow.py
@@ -6,24 +6,37 @@ from typing import Any
 
 import voluptuous as vol
 from homeassistant import config_entries
-from homeassistant.config_entries import ConfigEntry, OptionsFlow
+from homeassistant.config_entries import ConfigEntry, ConfigFlow, OptionsFlow
 from homeassistant.const import CONF_API_KEY, CONF_DESCRIPTION, CONF_ID, CONF_NAME
 from homeassistant.core import callback
-from homeassistant.data_entry_flow import FlowResult
+from homeassistant.data_entry_flow import FlowResult, FlowHandler
 
 from load_shedding import Provider, Province, get_areas
 from load_shedding.libs.sepush import SePush, SePushError
 from load_shedding.providers import ProviderError, Stage
-from .const import CONF_AREA_ID, CONF_AREAS, CONF_PROVIDER, CONF_SEARCH, DOMAIN, NAME
+from .const import (
+    CONF_AREA_ID,
+    CONF_AREAS,
+    CONF_PROVIDER,
+    CONF_SEARCH,
+    DOMAIN,
+    NAME,
+    CONF_ACTION,
+    CONF_ADD_AREA,
+    CONF_DELETE_AREA,
+    CONF_MULTI_STAGE_EVENTS,
+    CONF_MIN_EVENT_DURATION,
+    CONF_SETUP_API,
+)
 
 _LOGGER = logging.getLogger(__name__)
 
 
 @config_entries.HANDLERS.register(DOMAIN)
-class LoadSheddingFlowHandler(config_entries.ConfigFlow, domain=DOMAIN):
+class LoadSheddingFlowHandler(ConfigFlow, domain=DOMAIN):
     """Config flow for LoadShedding."""
 
-    VERSION = 3
+    VERSION = 4
 
     def __init__(self):
         self.provider: Provider = None
@@ -31,16 +44,16 @@ class LoadSheddingFlowHandler(config_entries.ConfigFlow, domain=DOMAIN):
         self.areas: dict = {}
         # self.device_unique_id = f"{DOMAIN}"
 
-    # @staticmethod
-    # @callback
-    # def async_get_options_flow(config_entry: ConfigEntry) -> OptionsFlow:
-    #     return LoadSheddingOptionsFlowHandler(config_entry)
+    @staticmethod
+    @callback
+    def async_get_options_flow(config_entry: ConfigEntry) -> OptionsFlow:
+        return LoadSheddingOptionsFlowHandler(config_entry)
 
     @classmethod
     @callback
     def async_supports_options_flow(cls, config_entry: ConfigEntry) -> bool:
         """Return options flow support for this handler."""
-        return False
+        return True
 
     async def async_step_user(
         self, user_input: dict[str, Any] | None = None
@@ -48,53 +61,7 @@ class LoadSheddingFlowHandler(config_entries.ConfigFlow, domain=DOMAIN):
         """Handle a flow initialized by the user."""
 
         await self._async_handle_discovery_without_unique_id()
-
-        # await self.async_set_unique_id(self.device_unique_id)
-        # self._abort_if_unique_id_configured()
-
-        return await self.async_step_sepush(None)
-
-    async def async_step_provider(
-        self, user_input: dict[str, Any] | None = None
-    ) -> FlowResult:
-        """Handle the flow step to search for and select an area."""
-        errors = {}
-        providers = {}
-
-        if not user_input:
-            user_input = {}
-
-        # Provider
-        if user_input and user_input.get(CONF_PROVIDER):
-            self.provider = Provider(user_input.get(CONF_PROVIDER))
-        default_provider = self.provider.value if self.provider else None
-        for provider in list(Provider):
-            if not default_provider:
-                default_provider = provider.value
-            providers[provider.value] = f"{provider}"
-
-        data_schema = vol.Schema({})
-
-        if not self.provider:
-            data_schema = data_schema.extend(
-                {
-                    vol.Required(CONF_PROVIDER, default=default_provider): vol.In(
-                        providers
-                    ),
-                }
-            )
-
-        if data_schema.schema:
-            return self.async_show_form(
-                step_id="provider",
-                data_schema=data_schema,
-                errors=errors,
-            )
-
-        if self.provider == Provider.SE_PUSH:
-            return await self.async_step_sepush(None)
-
-        return await self.async_step_lookup_areas(user_input)
+        return await self.async_step_sepush()
 
     async def async_step_sepush(
         self, user_input: dict[str, Any] | None = None
@@ -242,10 +209,9 @@ class LoadSheddingFlowHandler(config_entries.ConfigFlow, domain=DOMAIN):
         if area.province is not Province.UNKNOWN:
             description += f", {area.province}"
 
-        data = {
-            CONF_API_KEY: self.api_key,
-        }
+        data = {}
         options = {
+            CONF_API_KEY: self.api_key,
             CONF_AREAS: {
                 area.id: {
                     CONF_DESCRIPTION: description,
@@ -279,12 +245,12 @@ class LoadSheddingOptionsFlowHandler(OptionsFlow):
     """Load Shedding config flow options handler."""
 
     def __init__(self, config_entry: ConfigEntry) -> None:
-        """Initialize HACS options flow."""
-        self.config_entry: ConfigEntry = config_entry
-        self.options = dict(config_entry.options)
+        """Initialize options flow."""
+        # self.config_entry: ConfigEntry = config_entry
+        self.opts = dict(config_entry.options)
 
         self.provider = Provider.SE_PUSH
-        self.api_key = config_entry.data.get(CONF_API_KEY)
+        self.api_key = config_entry.options.get(CONF_API_KEY)
         self.areas = {}
 
     async def async_step_init(
@@ -292,27 +258,124 @@ class LoadSheddingOptionsFlowHandler(OptionsFlow):
     ) -> FlowResult:  # pylint: disable=unused-argument
         """Manage the options."""
 
-        # CONF_ACTIONS = {
-        #     CONF_ADD_DEVICE: "Add Area",
-        #     CONF_EDIT_DEVICE: "Remove Are",
-        # }
-
-        # CONFIGURE_SCHEMA = vol.Schema(
-        #     {
-        #         vol.Required(CONF_ACTION, default=CONF_ADD_DEVICE): vol.In(CONF_ACTIONS),
-        #     }
-        # )
-
-        schema: dict[vol.Marker, type] = {}
-        areas = self.options.get(CONF_AREAS, {})
-        for area_id, area in areas.items():
-            schema[vol.Required(area_id, default=True)] = vol.In(
-                {area_id: area.get(CONF_DESCRIPTION)}
-            )
+        CONF_ACTIONS = {
+            CONF_SETUP_API: "Configure API",
+            # CONF_ADD_AREA: "Add area",
+            # CONF_DELETE_AREA: "Remove area",
+            # CONF_MULTI_STAGE_EVENTS: ""
+        }
+
+        OPTIONS_SCHEMA = vol.Schema(
+            {
+                vol.Optional(CONF_ACTION): vol.In(CONF_ACTIONS),
+                vol.Optional(
+                    CONF_MULTI_STAGE_EVENTS,
+                    default=self.opts.get(CONF_MULTI_STAGE_EVENTS, False),
+                ): bool,
+                vol.Optional(
+                    CONF_MIN_EVENT_DURATION,
+                    default=self.opts.get(CONF_MIN_EVENT_DURATION, 30),
+                ): int,
+            }
+        )
+
+        if user_input is not None:
+            if user_input.get(CONF_ACTION) == CONF_SETUP_API:
+                return await self.async_step_sepush()
+            if user_input.get(CONF_ACTION) == CONF_ADD_AREA:
+                return await self.async_step_add_area()
+            # if user_input.get(CONF_ACTION) == CONF_DELETE_AREA:
+            #     return await self.async_step_delete_area()
+            self.opts[CONF_MULTI_STAGE_EVENTS] = user_input.get(CONF_MULTI_STAGE_EVENTS)
+            self.opts[CONF_MIN_EVENT_DURATION] = user_input.get(CONF_MIN_EVENT_DURATION)
+            return self.async_create_entry(title=NAME, data=self.opts)
 
-        return self.async_show_form(step_id="init", data_schema=vol.Schema(schema))
+        return self.async_show_form(
+            step_id="init",
+            data_schema=OPTIONS_SCHEMA,
+        )
+
+    async def async_step_sepush(
+        self, user_input: dict[str, Any] | None = None
+    ) -> FlowResult:
+        """Handle the flow step to configure SePush."""
+        self.provider = Provider.SE_PUSH
 
-        return await self.async_step_lookup_areas()
+        if not user_input:
+            user_input = {}
+
+        api_key = user_input.get(CONF_API_KEY)
+        errors = {}
+        if api_key:
+            try:
+                # Validate the token by checking the allowance.
+                sepush = SePush(token=api_key)
+                esp = await self.hass.async_add_executor_job(sepush.check_allowance)
+                _LOGGER.debug("Validate API Key Response: %s", esp)
+            except (SePushError) as err:
+                status_code = err.__cause__.args[0]
+                if status_code == 400:
+                    errors["base"] = "sepush_400"
+                elif status_code == 403:
+                    errors["base"] = "sepush_403"
+                elif status_code == 429:
+                    errors["base"] = "sepush_429"
+                elif status_code == 500:
+                    errors["base"] = "sepush_500"
+                else:
+                    errors["base"] = "provider_error"
+            else:
+                self.api_key = api_key
+                self.opts[CONF_API_KEY] = api_key
+                return self.async_create_entry(title=NAME, data=self.opts)
+
+        data_schema = vol.Schema(
+            {
+                vol.Required(CONF_API_KEY, default=self.api_key): str,
+            }
+        )
+        return self.async_show_form(
+            step_id="sepush",
+            data_schema=data_schema,
+            errors=errors,
+        )
+
+    # async def async_step_init(
+    #     self, user_input: dict[str, Any] | None = None
+    # ) -> FlowResult:  # pylint: disable=unused-argument
+    #     """Manage the options."""
+
+    #     CONF_ACTIONS = {
+    #         CONF_ADD_DEVICE: "Add Area",
+    #         CONF_EDIT_DEVICE: "Remove Area",
+    #     }
+
+    #     CONFIGURE_SCHEMA = vol.Schema(
+    #         {
+    #             vol.Required(CONF_ACTION, default=CONF_ADD_DEVICE): vol.In(
+    #                 CONF_ACTIONS
+    #             ),
+    #         }
+    #     )
+
+    #     return self.async_show_form(step_id="init", data_schema=vol.Schema(schema))
+
+    #     schema: dict[vol.Marker, type] = {}
+    #     areas = self.opts.get(CONF_AREAS, {})
+    #     for area_id, area in areas.items():
+    #         schema[vol.Required(area_id, default=True)] = vol.In(
+    #             {area_id: area.get(CONF_DESCRIPTION)}
+    #         )
+
+    #     return self.async_show_form(step_id="init", data_schema=vol.Schema(schema))
+
+    #     return await self.async_step_lookup_areas()
+
+    async def async_step_add_area(
+        self, user_input: dict[str, Any] | None = None
+    ) -> FlowResult:
+        """Handle the flow step to search for and select an area."""
+        return await self.async_step_lookup_areas(user_input=user_input)
 
     async def async_step_lookup_areas(
         self, user_input: dict[str, Any] | None = None
@@ -406,7 +469,7 @@ class LoadSheddingOptionsFlowHandler(OptionsFlow):
         self, user_input: dict[str, Any] | None = None
     ) -> FlowResult:
         """Handle the flow step to create a area."""
-        areas = self.options.get(CONF_AREAS, {})
+        areas = self.opts.get(CONF_AREAS, {})
         area = self.areas.get(user_input.get(CONF_AREA_ID))
 
         description = f"{area.name}"
@@ -421,13 +484,10 @@ class LoadSheddingOptionsFlowHandler(OptionsFlow):
             CONF_ID: area.id,
         }
 
-        self.options.update(
+        self.opts.update(
             {
                 CONF_AREAS: areas,
             }
         )
-        return await self._update_options()
-
-    async def _update_options(self):
-        """Update config entry options."""
-        return self.async_create_entry(title=NAME, data=self.options)
+        result = self.async_create_entry(title=NAME, data=self.opts)
+        return result
diff --git a/custom_components/load_shedding/const.py b/custom_components/load_shedding/const.py
index 90a15f4..704b0f7 100644
--- a/custom_components/load_shedding/const.py
+++ b/custom_components/load_shedding/const.py
@@ -11,7 +11,7 @@ NAME: Final = "Load Shedding"
 MANUFACTURER: Final = "@wernerhp"
 VERSION: Final = "1.1.0"
 DEFAULT_SCAN_INTERVAL: Final = 60
-AREA_UPDATE_INTERVAL: Final = 86400  # 60sec * 60min * 24h / daily
+AREA_UPDATE_INTERVAL: Final = 120  # 60sec * 60min * 24h / daily
 QUOTA_UPDATE_INTERVAL: Final = 1800  # 60sec * 30min
 STAGE_UPDATE_INTERVAL: Final = 3600  # 60sec * 60min / hourly
 
@@ -24,6 +24,12 @@ CONF_PROVINCE: Final = "province"
 CONF_PROVINCE_ID: Final = "province_id"
 CONF_SCHEDULE: Final = "schedule"
 CONF_SCHEDULES: Final = "schedules"
+CONF_ACTION = "action"
+CONF_ADD_AREA = "add_area"
+CONF_DELETE_AREA = "delete_area"
+CONF_SETUP_API = "setup_api"
+CONF_MULTI_STAGE_EVENTS = "multi_stage_events"
+CONF_MIN_EVENT_DURATION = "min_event_duration"
 CONF_API_KEY: Final = "api_key"
 CONF_AREA: Final = "area"
 CONF_AREAS: Final = "areas"
diff --git a/custom_components/load_shedding/manifest.json b/custom_components/load_shedding/manifest.json
index bd638b1..b520bbb 100644
--- a/custom_components/load_shedding/manifest.json
+++ b/custom_components/load_shedding/manifest.json
@@ -4,16 +4,12 @@
   "config_flow": true,
   "documentation": "https://github.com/wernerhp/ha_integration_load_shedding/blob/master/README.md",
   "issue_tracker": "https://github.com/wernerhp/ha_integration_load_shedding/issues",
-  "requirements": [
-    "load_shedding==0.11.5"
-  ],
+  "requirements": ["load_shedding==0.11.5"],
   "ssdp": [],
   "zeroconf": [],
   "homekit": {},
   "dependencies": [],
-  "codeowners": [
-    "@wernerhp"
-  ],
+  "codeowners": ["@wernerhp"],
   "iot_class": "cloud_polling",
-  "version": "1.1.0"
+  "version": "1.2.0"
 }
diff --git a/custom_components/load_shedding/sensor.py b/custom_components/load_shedding/sensor.py
index ea089ae..06640a7 100644
--- a/custom_components/load_shedding/sensor.py
+++ b/custom_components/load_shedding/sensor.py
@@ -71,7 +71,7 @@ async def async_setup_entry(
     """Add LoadShedding entities from a config_entry."""
     coordinators = hass.data.get(DOMAIN, {}).get(entry.entry_id)
     stage_coordinator = coordinators.get(ATTR_STAGE)
-    area_coordinator = coordinators.get(ATTR_AREA)
+    # area_coordinator = coordinators.get(ATTR_AREA)
     quota_coordinator = coordinators.get(ATTR_QUOTA)
 
     entities: list[Entity] = []
@@ -79,9 +79,9 @@ async def async_setup_entry(
         stage_entity = LoadSheddingStageSensorEntity(stage_coordinator, idx)
         entities.append(stage_entity)
 
-    for area in area_coordinator.areas:
-        area_entity = LoadSheddingAreaSensorEntity(area_coordinator, area)
-        entities.append(area_entity)
+    # for area in area_coordinator.areas:
+    #     area_entity = LoadSheddingAreaSensorEntity(area_coordinator, area)
+    #     entities.append(area_entity)
 
     quota_entity = LoadSheddingQuotaSensorEntity(quota_coordinator)
     entities.append(quota_entity)
@@ -176,11 +176,14 @@ class LoadSheddingStageSensorEntity(
                 data[ATTR_PLANNED].append(planned)
 
         cur_stage = Stage.NO_LOAD_SHEDDING
-        if planned := data[ATTR_PLANNED]:
+
+        planned = []
+        if ATTR_PLANNED in data:
+            planned = data[ATTR_PLANNED]
             cur_stage = planned[0].get(ATTR_STAGE, Stage.UNKNOWN)
 
-        attrs = get_sensor_attrs(data[ATTR_PLANNED], cur_stage)
-        attrs[ATTR_PLANNED] = data[ATTR_PLANNED]
+        attrs = get_sensor_attrs(planned, cur_stage)
+        attrs[ATTR_PLANNED] = planned
         attrs[ATTR_LAST_UPDATE] = self.coordinator.last_update
         attrs = clean(attrs)
 
@@ -195,110 +198,114 @@ class LoadSheddingStageSensorEntity(
             self.async_write_ha_state()
 
 
-class LoadSheddingAreaSensorEntity(
-    LoadSheddingDevice, CoordinatorEntity, RestoreSensor
-):
-    """Define a LoadShedding Area sensor entity."""
-
-    coordinator: CoordinatorEntity
-
-    def __init__(self, coordinator: CoordinatorEntity, area: Area) -> None:
-        """Initialize."""
-        super().__init__(coordinator)
-        self.area = area
-        self.data = self.coordinator.data.get(self.area.id)
-
-        self.entity_description = LoadSheddingSensorDescription(
-            key=f"{DOMAIN} schedule {area.id}",
-            icon="mdi:calendar",
-            name=f"{DOMAIN} schedule {area.name}",
-            entity_registry_enabled_default=True,
-        )
-        self._attr_unique_id = (
-            f"{self.coordinator.config_entry.entry_id}_sensor_{area.id}"
-        )
-        self.entity_id = f"{DOMAIN}.{DOMAIN}_area_{area.id}"
-
-    async def async_added_to_hass(self) -> None:
-        """Handle entity which will be added."""
-        if restored_data := await self.async_get_last_sensor_data():
-            self._attr_native_value = restored_data.native_value
-        await super().async_added_to_hass()
-
-    @property
-    def name(self) -> str | None:
-        return self.area.name
-
-    @property
-    def native_value(self) -> StateType:
-        """Return the area state."""
-        if not self.data:
-            return self._attr_native_value
-
-        events = self.data.get(ATTR_FORECAST, [])
-
-        if not events:
-            return self._attr_native_value
-
-        now = datetime.now(timezone.utc)
-
-        for event in events:
-            if ATTR_END_TIME in event and event.get(ATTR_END_TIME) < now:
-                continue
-
-            if event.get(ATTR_START_TIME) <= now <= event.get(ATTR_END_TIME):
-                self._attr_native_value = cast(StateType, STATE_ON)
-                break
-
-            if event.get(ATTR_START_TIME) > now:
-                self._attr_native_value = cast(StateType, STATE_OFF)
-                break
-
-            if event.get(ATTR_STAGE) == Stage.NO_LOAD_SHEDDING:
-                self._attr_native_value = cast(StateType, STATE_OFF)
-                break
-
-        return self._attr_native_value
-
-    @property
-    def extra_state_attributes(self) -> dict[str, list, Any]:
-        """Return the state attributes."""
-        if not hasattr(self, "_attr_extra_state_attributes"):
-            self._attr_extra_state_attributes = {}
-
-        if not self.data:
-            return self._attr_extra_state_attributes
-
-        now = datetime.now(timezone.utc)
-        data = dict(self._attr_extra_state_attributes)
-        if events := self.data.get(ATTR_FORECAST, []):
-            data[ATTR_FORECAST] = []
-            for event in events:
-                if ATTR_END_TIME in event and event.get(ATTR_END_TIME) < now:
-                    continue
-
-                forecast = {
-                    ATTR_STAGE: event.get(ATTR_STAGE),
-                    ATTR_START_TIME: event.get(ATTR_START_TIME),
-                    ATTR_END_TIME: event.get(ATTR_END_TIME),
-                }
-
-                data[ATTR_FORECAST].append(forecast)
-
-        attrs = get_sensor_attrs(data[ATTR_FORECAST])
-        attrs[ATTR_FORECAST] = data[ATTR_FORECAST]
-        attrs[ATTR_LAST_UPDATE] = self.coordinator.last_update
-        attrs = clean(attrs)
-
-        self._attr_extra_state_attributes.update(attrs)
-        return self._attr_extra_state_attributes
-
-    @callback
-    def _handle_coordinator_update(self) -> None:
-        """Handle updated data from the coordinator."""
-        if data := self.coordinator.data:
-            self.data = data.get(self.area.id)
-            self.async_write_ha_state()
+# class LoadSheddingAreaSensorEntity(
+#     LoadSheddingDevice, CoordinatorEntity, RestoreSensor
+# ):
+#     """Define a LoadShedding Area sensor entity."""
+
+#     coordinator: CoordinatorEntity
+
+#     def __init__(self, coordinator: CoordinatorEntity, area: Area) -> None:
+#         """Initialize."""
+#         super().__init__(coordinator)
+#         self.area = area
+#         self.data = self.coordinator.data.get(self.area.id)
+
+#         self.entity_description = LoadSheddingSensorDescription(
+#             key=f"{DOMAIN} schedule {area.id}",
+#             icon="mdi:calendar",
+#             name=f"{DOMAIN} schedule {area.name}",
+#             entity_registry_enabled_default=True,
+#         )
+#         self._attr_unique_id = (
+#             f"{self.coordinator.config_entry.entry_id}_sensor_{area.id}"
+#         )
+#         self.entity_id = f"{DOMAIN}.{DOMAIN}_area_{area.id}"
+
+#     async def async_added_to_hass(self) -> None:
+#         """Handle entity which will be added."""
+#         if restored_data := await self.async_get_last_sensor_data():
+#             self._attr_native_value = restored_data.native_value
+#         await super().async_added_to_hass()
+
+#     @property
+#     def name(self) -> str | None:
+#         return self.area.name
+
+#     @property
+#     def native_value(self) -> StateType:
+#         """Return the area state."""
+#         if not self.data:
+#             return self._attr_native_value
+
+#         events = self.data.get(ATTR_FORECAST, [])
+
+#         if not events:
+#             return STATE_OFF
+
+#         now = datetime.now(timezone.utc)
+
+#         for event in events:
+#             if ATTR_END_TIME in event and event.get(ATTR_END_TIME) < now:
+#                 continue
+
+#             if event.get(ATTR_START_TIME) <= now <= event.get(ATTR_END_TIME):
+#                 self._attr_native_value = cast(StateType, STATE_ON)
+#                 break
+
+#             if event.get(ATTR_START_TIME) > now:
+#                 self._attr_native_value = cast(StateType, STATE_OFF)
+#                 break
+
+#             if event.get(ATTR_STAGE) == Stage.NO_LOAD_SHEDDING:
+#                 self._attr_native_value = cast(StateType, STATE_OFF)
+#                 break
+
+#         return self._attr_native_value
+
+#     @property
+#     def extra_state_attributes(self) -> dict[str, list, Any]:
+#         """Return the state attributes."""
+#         if not hasattr(self, "_attr_extra_state_attributes"):
+#             self._attr_extra_state_attributes = {}
+
+#         if not self.data:
+#             return self._attr_extra_state_attributes
+
+#         now = datetime.now(timezone.utc)
+#         data = dict(self._attr_extra_state_attributes)
+#         if events := self.data.get(ATTR_FORECAST, []):
+#             data[ATTR_FORECAST] = []
+#             for event in events:
+#                 if ATTR_END_TIME in event and event.get(ATTR_END_TIME) < now:
+#                     continue
+
+#                 forecast = {
+#                     ATTR_STAGE: event.get(ATTR_STAGE),
+#                     ATTR_START_TIME: event.get(ATTR_START_TIME),
+#                     ATTR_END_TIME: event.get(ATTR_END_TIME),
+#                 }
+
+#                 data[ATTR_FORECAST].append(forecast)
+
+#         forecast = []
+#         if ATTR_FORECAST in data:
+#             forecast = data[ATTR_FORECAST]
+
+#         attrs = get_sensor_attrs(forecast)
+#         attrs[ATTR_FORECAST] = forecast
+#         attrs[ATTR_LAST_UPDATE] = self.coordinator.last_update
+#         attrs = clean(attrs)
+
+#         self._attr_extra_state_attributes.update(attrs)
+#         return self._attr_extra_state_attributes
+
+#     @callback
+#     def _handle_coordinator_update(self) -> None:
+#         """Handle updated data from the coordinator."""
+#         if data := self.coordinator.data:
+#             self.data = data.get(self.area.id)
+#             self.async_write_ha_state()
 
 
 class LoadSheddingQuotaSensorEntity(
diff --git a/custom_components/load_shedding/strings.json b/custom_components/load_shedding/strings.json
index 1e007ed..5626139 100644
--- a/custom_components/load_shedding/strings.json
+++ b/custom_components/load_shedding/strings.json
@@ -43,6 +43,23 @@
   },
   "options": {
     "step": {
+      "init": {
+        "title": "Load Shedding Configuration",
+        "description": "Please select the desired action.",
+        "data": {
+          "add_area": "Add area",
+          "delete_area": "Remove area",
+          "setup_api": "Configure API",
+          "multi_stage_events": "Multi-stage events",
+          "min_event_duration": "Min. event duration (mins)"
+        }
+      },
+      "sepush": {
+        "description": "Get a Free (50 requests per day) API Key from [Eskom Se Push](https://eskomsepush.gumroad.com/l/api).",
+        "data": {
+          "api_key": "API Key / Token"
+        }
+      },
       "lookup_areas": {
         "description": "Search your area name, e.g. Milnerton, then select your area ID from the results.",
         "data": {
@@ -55,6 +72,16 @@
           "area_id": "Area"
         }
       }
+    },
+    "error": {
+      "cannot_connect": "[%key:common::config_flow::error::cannot_connect%]",
+      "provider_error": "Unable to reach Provider.  See Logs for details.",
+      "no_results_found": "No results found.  Try searching for a different area with the same schedule as yours or choose a different provider.",
+      "no_provider": "No provider selected.",
+      "sepush_400": "Bad request. Create a issue for the integration and include logs.",
+      "sepush_403": "Invalid API Key / Token",
+      "sepush_429": "Token quota exceeded",
+      "sepush_500": "SePush server unavailable"
     }
   }
 }
diff --git a/custom_components/load_shedding/translations/en.json b/custom_components/load_shedding/translations/en.json
index 6ea19d3..2944b1e 100644
--- a/custom_components/load_shedding/translations/en.json
+++ b/custom_components/load_shedding/translations/en.json
@@ -42,7 +42,28 @@
         }
     },
     "options": {
+        "error": {
+            "cannot_connect": "Failed to connect",
+            "no_provider": "No provider selected.",
+            "no_results_found": "No results found.  Try searching for a different area with the same schedule as yours or choose a different provider.",
+            "provider_error": "Unable to reach Provider.  See Logs for details.",
+            "sepush_400": "Bad request. Create a issue for the integration and include logs.",
+            "sepush_403": "Invalid API Key / Token",
+            "sepush_429": "Token quota exceeded",
+            "sepush_500": "SePush server unavailable"
+        },
         "step": {
+            "init": {
+                "data": {
+                    "add_area": "Add area",
+                    "delete_area": "Remove area",
+                    "min_event_duration": "Min. event duration (mins)",
+                    "multi_stage_events": "Multi-stage events",
+                    "setup_api": "Configure API"
+                },
+                "description": "Please select the desired action.",
+                "title": "Load Shedding Configuration"
+            },
             "lookup_areas": {
                 "data": {
                     "area": "Area",
@@ -54,6 +75,12 @@
                     "search": "Search"
                 },
                 "description": "Search your area name, e.g. Milnerton, then select your area ID from the results."
+            },
+            "sepush": {
+                "data": {
+                    "api_key": "API Key / Token"
+                },
+                "description": "Get a Free (50 requests per day) API Key from [Eskom Se Push](https://eskomsepush.gumroad.com/l/api)."
             }
         }
     }
